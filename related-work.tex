\section{Related Work}
Our work uses RL techniques to improve upon results in recent TAMP systems.
We train good policies for sampling plan variable values, whereas other
systems use hand-coded heuristics to guide this sampling.

Srivastava et al.~\cite{srivastava2014combined} hand-tune coarse, domain-specific discretizations
for determining the robot pose in actions such as moving the base and picking up an object from a table.
Kaelbling et al.~\cite{kaelbling2011hierarchical} use ``geometric suggesters'' to propose
continuous geometric values for the plan parameters. These suggesters are heuristic
computations which map information about the robot type and geometric operators to a restricted
set of values to sample for each plan parameter. Lagriffoul et al.~\cite{lagriffoul2014orientation}
propose a set of geometric constraints involving the kinematics and sizes of the specific objects of
interest in the environment. These constraints then define a feasible region from which to search
for geometric instantiations of plan parameters. Garrett et al.~\cite{GarrettWAFR14} use information
about reachability in the robot configuration space and symbolic state space to construct a
\emph{relaxed plan graph} that guides motion planning queries, using geometric biases to break ties
among states with the same heuristic value.

By contrast to these systems, our method learns continuous sampling distributions for plan variables,
which are significantly more robust to different environment layouts.

Prior work has been devoted to using machine learning techniques for
training heuristics to guide search algorithms. This general formulation
has been applied to many domains other than hierarchical planning for robotics.

Boyan et al.~\cite{Boyanlearning} present an application to solving optimization
problems using local search routines. They describe an algorithm, \textsc{Stage},
for learning a state evaluation function using features of the optimization problem.
This function then guides the local search toward better optima.

Arbelaez et al.~\cite{hamadisearch} use machine learning to solve constraint
satisfaction problems (CSPs). Their approach, Continuous Search, maintains a heuristic
model for solving CSPs and alternates between two modes. In the \emph{exploitation} mode,
the current heuristic model is used to solve user-inputted CSPs. In the \emph{exploration}
mode, this model is refined using supervised learning with a linear SVM.

Xu et al.~\cite{Xu07discriminativelearning} apply machine learning for classical task
planning, drawing inspiration from recent advances in discriminative learning for
structured output classification. Their system trains heuristics for controlling forward
state-space beam search in task planners.

To our knowledge, our work is the first to use RL for plan refinement in a TAMP system.
