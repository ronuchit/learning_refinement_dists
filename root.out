\BOOKMARK [1][-]{section.1}{Introduction}{}
\BOOKMARK [1][-]{section.2}{Related Work}{}
\BOOKMARK [1][-]{section.3}{Formalization}{}
\BOOKMARK [2][-]{subsection.3.1}{Task Planning}{section.3}
\BOOKMARK [2][-]{subsection.3.2}{Task and Motion Planning[TO DO SID]}{section.3}
\BOOKMARK [2][-]{subsection.3.3}{Markov Decision Processes and Reinforcement Learning}{section.3}
\BOOKMARK [2][-]{subsection.3.4}{Reinforcement Learning for Planning}{section.3}
\BOOKMARK [1][-]{section.4}{Overall Algorithm[TO DO SID]}{}
\BOOKMARK [2][-]{subsection.4.1}{Plan Refinement Graph[TO DO SID]}{section.4}
\BOOKMARK [2][-]{subsection.4.2}{Proof of Completeness[TO DO SID]}{section.4}
\BOOKMARK [2][-]{subsection.4.3}{Guided Search Techniques[TO DO SID]}{section.4}
\BOOKMARK [1][-]{section.5}{Randomized Refinement}{}
\BOOKMARK [1][-]{section.6}{Learning Refinement Distributions}{}
\BOOKMARK [2][-]{subsection.6.1}{Formulation as Reinforcement Learning Problem}{section.6}
\BOOKMARK [2][-]{subsection.6.2}{Training Process}{section.6}
\BOOKMARK [2][-]{subsection.6.3}{Distribution and Gradient Updates}{section.6}
\BOOKMARK [1][-]{section.7}{Selecting a Plan to Try Refining}{}
\BOOKMARK [1][-]{section.8}{Experiments}{}
\BOOKMARK [2][-]{subsection.8.1}{Training Methodology}{section.8}
\BOOKMARK [2][-]{subsection.8.2}{Can Domain}{section.8}
\BOOKMARK [2][-]{subsection.8.3}{Dinner Domain}{section.8}
\BOOKMARK [1][-]{section.9}{Conclusion}{}
\BOOKMARK [1][-]{section*.4}{References}{}
