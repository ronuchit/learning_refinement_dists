\begin{abstract}
In mobile manipulation planning, it is not uncommon for tasks to require thousands of
individual motions. Such problems require
reasoning about courses of action from the viewpoint of logical
objectives as well as the feasibility of individual movements in the
configuration space. In discrete representations, planning complexity
is exponential in the length of the plan; in mobile manipulation, the
set of parameters for an action is often continuous, so we must also
cope with an infinite branching factor. Recent work on \emph{task and
  motion planning} (TAMP) attempts to address this challenge. TAMP
methods integrate logical search with continuous geometric reasoning
in order to sequence several short-horizon motion plans that together
solve a long-horizon task. In this work, we present an algorithm for
searching in the space of possible task and motion plans by building
on prior work for factoring the planning problem into components for
logical and geometric reasoning. In contrast to prior work in the
field, we develop novel techniques for using statistical machine learning to
guide the search process. Our contributions are as follows: 1)
we present a complete algorithm for TAMP; 2) we present a randomized
local search algorithm for TAMP that is easily formulated
as a Markov decision process (MDP); 3) we give a reinforcement learning (RL) algorithm that
learns a policy for this MDP; 4) we present a method that trains
heuristics for intelligently searching the available space of task plans,
given options that address different infeasibilities; and 5)
we run experiments to evaluate the performance of our system in a
variety of simulated domains. We show significant improvements in
performance over the system we build on.
\end{abstract}
