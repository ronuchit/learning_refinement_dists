\begin{abstract}
Tasks in mobile manipulation planning often require thousands of individual
motions to complete. Such tasks require
reasoning about logical
objectives as well as the feasibility of movements in
configuration space. In discrete representations, planning complexity
is exponential in the length of the plan; in mobile manipulation,
parameters for an action often draw from a continuous space, so we must also
cope with an infinite branching factor.
\emph{Task and motion planning} ({\sc tamp})
methods integrate a logical search over high-level actions with continuous geometric reasoning
to address this challenge. We present an algorithm that
searches the space of possible task and motion plans, using statistical machine learning to
guide the search process. Our contributions are as follows: 1)
we present a complete algorithm for {\sc tamp}; 2) we present a randomized
local search algorithm for {\sc tamp} that is easily formulated
as a Markov decision process ({\sc mdp}); 3) we apply reinforcement learning ({\sc rl}) to learn
a policy for this {\sc mdp}; 4) we learn from expert demonstrations to
efficiently search the space of task plans,
given options that address different infeasibilities; and 5)
we run experiments to evaluate the performance of our system in a
variety of simulated domains. We show significant improvements in
performance over the system we build on.
\end{abstract}
