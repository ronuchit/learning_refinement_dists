\section{Solving Task and Motion Planning Problems}
Solving TAMP problems requires evaluation of
possible courses of action comprised of different combinations of
instantiated action operators. This is particularly challenging
because the set of possible action instantiations (and thus the
branching factor of the underlying search problem) is infinite.
We give a brief overview of SFRCRA-14, a recent approach to TAMP, and
refer the interested reader to the cited paper for further details.
Then, we present a complete algorithm for TAMP that we implemented in
the framework of SFRCRA-14.

\subsection{Preliminaries}
Intuitively, SFRCRA-14 conducts a greedy search by incrementally searching for a symbolic
plan that solves the high-level abstraction of the given TAMP problem;
determining a prefix of the plan that has a motion planning feasible refinement; updating the high-level abstraction to reflect the
reason for infeasibility; and searching for a new plan suffix from the failure step onwards.

In general, including geometric properties in the logic-based formulation leads to an
increase in the number of objects representing distinct poses and/or trajectories. For
instance, expressing the fact that a trajectory for grasping \emph{can$_1$} is obstructed by
\emph{can$_3$} from the current pose of the robot would require setting a fluent of the
form \emph{obstructs(can$_3$, pose$_{17877}$, trajectory$_{3219}$, can$_1$)} to true in
the description of the high-level state. In turn, this would require adding
\emph{pose$_{17877}$} and \emph{trajectory$_{3219}$} into the set of objects if they were
not already included. Unfortunately, the size of the abstracted, logic-based state space
grows exponentially with the number of objects, and such an approach quickly leads to
unsolvable task planning problems.

SFRCRA-14 addresses this challenge by abstracting the continuous action
arguments, such as robot grasping poses and trajectories, into a
\emph{bounded} set of symbolic references to potential values. A
\emph{symbolic}, or \emph{high-level}, plan refers to the fixed task
sequence returned by a task planner and comprised of these symbolic
references. An \emph{interface layer} conducts plan refinement, searching for instantiations of
continuous values to symbolic references while ensuring action
feasibility. The authors introduce an algorithm called \textsc{TryRefine}, an exhaustive backtracking search over
the hand-coded, discretized space of instantiations for each symbolic reference.
The resulting process is able to utilize off-the-shelf task and motion
planners while carrying out the necessary exchange of information in a
scalable manner. However, the algorithm is not complete in all situations: it may
not find a solution to a solvable problem.

\subsection{A Complete Algorithm}
We introduce a complete algorithm that maintains a \emph{plan refinement graph}, whose
nodes each store a valid symbolic plan and its current set of
instantiated symbolic reference values. If the refinement of a plan $p$ stored in
node $n$ leads to discovered facts being propagated to the task
planner, the newly produced plan $p'$ based on the updated fluent
state is added as a child node $n'$ of $n$. This makes it possible to
divide computational effort between the search for additional
high-level plans that resolve specific errors in previous ones, and
the search for error-free refinements of existing plans.
The greedy search used in SFRCRA-14 can be viewed as depth-first search
through this graph. (KEEP THIS SENTENCE)

\begin{algorithm}[t]
\begin{small}
  \SetAlgoLined
  \DontPrintSemicolon
  \SetKwFunction{algo}{algo}\SetKwFunction{proc}{proc}
  \SetKwProg{myalg}{Algorithm}{}{}
  \SetKwProg{myproc}{Subroutine}{}{}
  \myalg{Complete TAMP}{
    \nl \For{trial in 1 ...}{
      \nl  \For{j in 1 .. trial}{
        \tcc{\footnotesize Traverse graph of plans, initially with just one plan:
          $\epsilon$.}
        \nl $\pi \leftarrow$ \textsc{GetNextPlanFromGraph}()\;
        \nl \textsc{ProcessRefs}($\pi$, $j$, ChunkSize)\;
        \nl \textsc{ReweighPlansInGraph}()        \;}}
  }
  \;
  \setcounter{AlgoLine}{0}
  \myproc{\textsc{ProcessRefs}($\pi$, $j$, ChunkSize)}{
    \nl ValueSet = \textsc{GetValueSet}($\pi$, resourceLimit, $j$, ChunkSize)\;
    \nl \For{$\sigma$ in ValueSet}{
        \nl  $MP \leftarrow$ \textsc{GetMotionPlan}($\sigma$, $\pi$, resourceLimit)\;
        \nl \If{MP $\ne$ NULL}{
            \nl return success
       	}
      }
    \nl \For{$\sigma$ in ValueSet}{
        \nl LastReachableSt, FailedPrecon $\leftarrow$ \textsc{TryGetMP}($\sigma$, $\pi$)\;
        \tcc{\footnotesize Make last reachable state unsolvable if FailedPrecon not found.}
        \nl TrueLRState $\leftarrow$ \textsc{Patch}(LastReachableSt, FailedPrecon)\;
        \nl \tcc{\footnotesize Disallow all states up to and including LastReachableSt.}
        \nl Dom2 $\leftarrow$ \textsc{DisallowHistory}(Dom, $\pi$, LastReachableSt)\; 
        \nl \textsc{ProcessSDH}(TrueLRState, Dom2, $\pi$, $\sigma$)\;
      }
  }
  \;
  \setcounter{AlgoLine}{0}
  \myproc{\textsc{ProcessSDH}(State, Domain, PlanHistory, Interp)}{
    \nl SDHTuple = $\langle$ State, Domain, PlanHistory, Interp $\rangle$\;
	\nl plan = \textsc{GetClassicalPlan}(SDHTuple)\;
    \nl \If{plan == NULL}{
    	        \tcc{\footnotesize Disallow action which led to failure state from
                  previous state.}
        	\nl State2, History2 $\leftarrow$ \textsc{GetPredecessors}(SDHTuple)\;
        	\nl Dom2 $\leftarrow$ \textsc{DisallowActionInState}(Domain, State2, \textsc{LastAction}(History2))\;
        	\nl \textsc{ProcessSDH}(State2, Dom2, History2)\;}
	\nl \Else{
                \tcc{\footnotesize Add plan with edge from parent.}
                \nl \textsc{AddToPlanGraph}(plan, \textsc{History}(SDHTuple))}
}
\end{small}
\label{alg-completetamp}
\vspace{-1.5 em}
\end{algorithm}

TODO Sid: explain algorithm, simplify algorithm

\subsection{Proof of Completeness[TODO Sid]}

\subsection{Guided Search Techniques[TODO Sid]}
You can use any guided search technique to explore the PRgraph